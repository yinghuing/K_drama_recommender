{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinghuing/K_drama_recommender/blob/master/chapter5/implement_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 0: ハンズオンの準備\n",
        "---"
      ],
      "metadata": {
        "id": "2SXS3qjHO5J9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリのインストール"
      ],
      "metadata": {
        "id": "hjpQpmcrkcA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain langchain-openai langchain-community langchainhub langgraph tavily-python chromadb tiktoken"
      ],
      "metadata": {
        "id": "xNJhQoCptr7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.7 langchain-community==0.3.7 langchain-core==0.3.18 langchain-openai==0.2.9 langchain-text-splitters==0.3.2 langgraph==0.2.52 langgraph-checkpoint==2.0.5 langchainhub==0.1.21 tavily-python chromadb tiktoken"
      ],
      "metadata": {
        "id": "5L-ErUJuMtEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2795c978-f373-4a19-f9a8-fd7eaa8b50a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m880.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep langchain"
      ],
      "metadata": {
        "id": "15QyqnKk1CTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2455ee-934e-4b7e-a13f-5f88b75c4a7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain==0.3.7\n",
            "langchain-community==0.3.7\n",
            "langchain-core==0.3.18\n",
            "langchain-openai==0.2.9\n",
            "langchain-text-splitters==0.3.2\n",
            "langchainhub==0.1.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep langgraph"
      ],
      "metadata": {
        "id": "z_GuZmGf1gKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f1df89-9e7f-4cac-df18-aa3e971d6fd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langgraph==0.2.52\n",
            "langgraph-checkpoint==2.0.5\n",
            "langgraph-sdk==0.1.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API キーの設定\n",
        "*  左ナビゲーションで [**シークレット**] アイコン (鍵形のアイコン) をクリックします。\n",
        "*  [**新しいシークレットを追加**] をクリックし、`LANGCHAIN_API_KEY`、`OPENAI_API_KEY`、`TAVILY_API_KEY` の 3 つを設定し、[**ノートブックからのアクセス**] を有効にします\n",
        "  *  `OPENAI_API_KEY` の [**値**] には指定されたキーを入力します。\n",
        "  *  `LANGCHAIN_API_KEY` と `TAVILY_API_KEY` の [**値**] にはご自身で取得したキーを入力してください。\n",
        "*  入力が完了したら、下のセルを実行します。"
      ],
      "metadata": {
        "id": "7Xq-T4gzi4ga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r3-Ha_aLspoO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "pclZg_IOh173"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: LangGraph の基本\n",
        "---\n",
        "https://langchain-ai.github.io/langgraph/  \n",
        "[Intro to LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)"
      ],
      "metadata": {
        "id": "IORhWlqn8Fgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基本のチャットボットを作成する"
      ],
      "metadata": {
        "id": "O8mtRsNxExM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### State と Graph\n",
        "State は `messages` (Message のリスト) として状態を保持する。  \n",
        "[StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph)"
      ],
      "metadata": {
        "id": "PGqsSKUgBqPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# State を定義\n",
        "class State(TypedDict):\n",
        "    # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Graph (StateGraph) のインスタンスを作成\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "wHbCdUr2sd_n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node"
      ],
      "metadata": {
        "id": "epkfSxhhSxRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WY3sdyngepk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e97d97-bcd5-4c9c-ee77-8fff376b792a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7ca4fcfb10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Chat model を用意\n",
        "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "\n",
        "# Node を定義\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [model.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Node を Graph に追加\n",
        "## 第 1 引数は Node の名前\n",
        "## 第 2 引数は Node の関数/オブジェクト\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.set_entry_point(\"chatbot\")"
      ],
      "metadata": {
        "id": "NN7N7UKx4Vp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddda431-07ab-4f30-ab53-01273718ffb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7ca4fcfb10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.set_finish_point(\"chatbot\")"
      ],
      "metadata": {
        "id": "kItYTNZB4WdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df01026-dae0-4d90-ac3d-688b2168c865"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7ca4fcfb10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph のコンパイル"
      ],
      "metadata": {
        "id": "f_HZ9x03DeI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "rflzG6iL4bbK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph の可視化"
      ],
      "metadata": {
        "id": "uUjJ5tDqDw1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "2lRlpFd44ylg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "c3725675-9c6c-4362-8767-b5a15d551ced"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph の実行"
      ],
      "metadata": {
        "id": "br8y2kniDzo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"messages\": [(\"user\", \"LangGraph とは何か教えてください。\")]})"
      ],
      "metadata": {
        "id": "cav-xTEvZ1Fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31b35ac-073a-4562-c3f8-e59b99d061f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='LangGraph とは何か教えてください。', additional_kwargs={}, response_metadata={}, id='bf14dae0-c760-4979-8036-e78739bfbdc2'),\n",
              "  AIMessage(content='LangGraphは、自然言語処理（NLP）や機械学習の分野で使用される技術やフレームワークの一つで、特に言語モデルやテキストデータの処理に関連しています。具体的には、LangGraphは言語の構造や意味をグラフ形式で表現し、テキストデータの分析や生成を行うための手法を提供します。\\n\\nLangGraphの主な特徴には以下のようなものがあります：\\n\\n1. **グラフ構造**: 言語の要素（単語、フレーズ、文など）をノードとして、これらの要素間の関係をエッジとして表現します。これにより、言語の構造を視覚的に理解しやすくなります。\\n\\n2. **意味的関係の把握**: グラフを用いることで、単語やフレーズの意味的な関係をより深く理解することが可能になります。例えば、同義語や対義語、関連語などの関係を明示化できます。\\n\\n3. **情報の統合**: 異なる情報源からのデータを統合し、より豊かな文脈を持つテキスト生成や分析が可能になります。\\n\\n4. **応用範囲**: LangGraphは、テキスト生成、要約、質問応答、感情分析など、さまざまなNLPタスクに応用できます。\\n\\n具体的な実装や使用例については、LangGraphに関連する研究やプロジェクトによって異なるため、興味がある場合は最新の文献やリソースを参照することをお勧めします。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 392, 'prompt_tokens': 17, 'total_tokens': 409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-d62e0b44-c62d-4070-96d9-0bfffc5dcdcf-0', usage_metadata={'input_tokens': 17, 'output_tokens': 392, 'total_tokens': 409, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event = graph.invoke({\"messages\": [(\"user\", \"LangGraph とは何か教えてください。\")]})\n",
        "print(event[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "AC9mG99NFmuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6831f5a-9deb-4fd5-c12a-a3f655dfb34b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraphは、自然言語処理（NLP）や機械学習の分野で使用される技術やフレームワークの一つで、特に言語データをグラフ構造で表現することに焦点を当てています。具体的には、言語の構造や意味をグラフとしてモデル化することで、より深い理解や解析を可能にすることを目的としています。\n",
            "\n",
            "LangGraphの主な特徴には以下のようなものがあります：\n",
            "\n",
            "1. **グラフ構造**: 言語の要素（単語、フレーズ、文など）をノードとして、これらの要素間の関係をエッジとして表現します。これにより、言語の構造を視覚的に理解しやすくなります。\n",
            "\n",
            "2. **意味的関係の表現**: 単語やフレーズの意味的な関係をグラフで表現することで、文脈や関連性を考慮した解析が可能になります。\n",
            "\n",
            "3. **情報検索や質問応答**: LangGraphを用いることで、情報検索や質問応答システムの精度を向上させることができます。グラフ構造を利用することで、関連情報を効率的に取得することができます。\n",
            "\n",
            "4. **機械学習との統合**: LangGraphは、機械学習アルゴリズムと組み合わせることで、より高度な言語処理タスクに対応することができます。\n",
            "\n",
            "LangGraphは、特に複雑な言語データの解析や処理において、従来の手法よりも優れたパフォーマンスを発揮する可能性があります。具体的な実装や応用例については、研究論文やプロジェクトのドキュメントを参照することが有益です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    event = graph.invoke({\"messages\": (\"user\", user_input)})\n",
        "    print(\"Assistant:\", event[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "I74txK125DyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df88b1f-6ce0-4a7d-d31d-b2f411c3bc93"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: luck of scorpio today\n",
            "Assistant: I don't have real-time data or daily horoscopes, but I can provide a general idea of what Scorpios might expect based on typical astrological interpretations. Scorpios are often seen as passionate, resourceful, and determined individuals. \n",
            "\n",
            "For a typical day, Scorpios might focus on:\n",
            "\n",
            "1. **Emotional Depth**: You may find yourself reflecting on your feelings and relationships. It's a good time to connect with loved ones or address any unresolved issues.\n",
            "\n",
            "2. **Career Focus**: Your determination could lead to breakthroughs at work. Trust your instincts and be open to new opportunities.\n",
            "\n",
            "3. **Health and Well-being**: Pay attention to your physical and mental health. Consider engaging in activities that promote relaxation and stress relief.\n",
            "\n",
            "4. **Intuition**: Your intuition may be particularly strong today. Trust your gut feelings when making decisions.\n",
            "\n",
            "For a more personalized reading, consider checking a reliable astrology website or app for today's specific horoscope for Scorpio.\n",
            "User: quit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools\n",
        "https://python.langchain.com/docs/concepts/#tools  \n",
        "https://python.langchain.com/docs/how_to/#tools  \n",
        "https://python.langchain.com/docs/integrations/tools/"
      ],
      "metadata": {
        "id": "TpSBwtpuoGnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tavily Search\n",
        "*  Tool として Tavily Search を使用する。\n",
        "*  この Tool は、インターネット検索をする機能を提供する。\n",
        "\n",
        "[langchain_community.tools.tavily_search.tool.TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html)"
      ],
      "metadata": {
        "id": "lCLDIgFdQwtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# TavilySearchResults のインスタンスを作成\n",
        "tool = TavilySearchResults(max_results=10)\n",
        "\n",
        "# Tool のリストを作成\n",
        "tools = [tool]\n",
        "\n",
        "# Tool も Runnable であり invoke メソッドで実行できる\n",
        "tool.invoke(\"LangGraph におけるノードとは何ですか。\")"
      ],
      "metadata": {
        "id": "WedKS69VpIPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9464fd-29b2-4e16-8293-eee5078792ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://qiita.com/ikedachin/items/2e7197ea87861247425f',\n",
              "  'content': 'LangGraph は node と edge と state の理解が必要です。 node ：何かしら処理をするところ; state ： node で処理した内容を記憶した状態; edge'},\n",
              " {'url': 'https://note.com/astropomeai/n/ncabaf9c06a55',\n",
              "  'content': '上流ノード：このノードの出力が次に何をするかを決定するために見られます。 関数：これは次にどのノードを呼び出すかを決定するために呼ばれます。文字列'},\n",
              " {'url': 'https://note.com/hatti8/n/n40bccb8bf662',\n",
              "  'content': 'ツールノード（LLMを使わない処理ノードをツールノードと呼ぶ？）、エージェントをadd_nodeを使ってノードとして追加。 エッジ、条件付きエッジを追加する'},\n",
              " {'url': 'https://book.st-hakky.com/data-science/langgraph-intro/',\n",
              "  'content': 'このページの見出し\\n執筆者：Hakky社メンバー\\nLangGraphとは？サンプルコードをもとにわかりやすく解説！\\nはじめに\\u200b\\nこれまでの LangChain は一本の鎖のように A=>B=>C というように、処理が連続していて一方向にデータが流れていく構造でした。 LangGraph の登場によって簡単にサイクル（繰り返し循環する）を実装することができるようになりました。 LangChain についてはLangChain とは？各モジュールの機能と活用事例まとめやLangChain のエージェントについてで解説しています。\\nLangGraph の全体像\\u200b\\nそれでは公式のサンプルに沿って実装しながら解説していきます。 公式ではTavilyという検索ツールを使って、学習データにない情報を取得して質問に答えるというサンプルが紹介されています。 完全なコードは公式のサンプルを参照してください。\\n今回はこのような循環する二つのノードのグラフを作成します。 [...] 2024年6月18日に最終更新\\n前へ LangFlow とは次へ LangGraph+StreamlitでStreamling\\n資料請求 ---- Hakkyの案件事例や提供するソリューションを確認する\\nメールマガジン ------- データ・AIに関するHakky独自の考察を受け取る\\nお問い合わせ ------ AIプロダクトやデータ活用のお悩みをHakkyに無料相談する\\n\\nはじめに\\nLangGraph の全体像\\nノードの処理の解説\\nグラフの実行\\n参考文献\\n\\n\\n株式会社Hakky\\n〒160-0022 東京都新宿区新宿五丁目18番20号\\nルックハイツ新宿803号\\nHandbook\\n\\n業界から事例を探す\\n業務から事例を探す\\n導入目的・課題から事例を探す\\nBlogをみる\\nNewsをみる\\nウェビナーをみる\\n\\nService\\n\\nデータ活用支援\\n機械学習プロダクト開発支援\\nデータ基盤構築支援\\n\\nProduct\\n\\nFindVox\\naigleApp\\n\\nAbout Us\\n\\nCompany\\nStackshare\\n採用情報\\nニュース [...] from langgraph.graph import StateGraph, END# 新しいグラフを定義workflow = StateGraph(AgentState)#先ほどの図の二つのノードを定義workflow.add_node(\"agent\", call_model)workflow.add_node(\"action\", call_tool)#エントリーポイントをagentに設定(一番初めに呼ばれる)workflow.set_entry_point(\"agent\")#agent →action という条件付きエッジを作成workflow.add_conditional_edges(    #開始ノードを指定    \"agent\",    #条件が定義されどのノードを呼ぶか判断する関数を指定    should_continue,    {        #続けるのならばactionノードを呼ぶ        \"continue\": \"action\",        #続けないのならばENDノードを呼ぶ（ライブラリによって実装済み）        \"end\": END'},\n",
              " {'url': 'https://qiita.com/taka_yayoi/items/311048184657aa8ad53f',\n",
              "  'content': \"条件付きエッジは単一のノードから始まることに注意してください。これはグラフに「' chatbot 'ノードが実行されるたびに、ツールを呼び出す場合は' tools\"},\n",
              " {'url': 'https://www.youtube.com/watch?v=CvqQFqRLjeQ',\n",
              "  'content': '【第35回】LangGraphのノード・エッジ・ルーティングを深堀り - 西岡賢一郎 · Comments.'},\n",
              " {'url': 'https://zenn.dev/hakoten/articles/b46253e6eee78b',\n",
              "  'content': 'Functional API は、LangGraph が提供する新しいLLM実行環境を構築するためのAPIです。 これまで、LangGraphは有向非巡回グラフ（DAG）を構築するGraph'},\n",
              " {'url': 'https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langgraph',\n",
              "  'content': '01はじめに02プロンプトエンジニアとは？03プロンプトエンジニアの必須スキル5選04プロンプトデザイン入門【質問テクニック10選】05LangChainの概要と使い方06LangChainのインストール方法【Python】07LangChainのインストール方法【JavaScript・TypeScript】08LCEL（LangChain Expression Language）の概要と使い方09LangSmithの概要と使い方【LLMOps】10LangServeの概要と使い方【API】11LangGraphの概要と使い方【Multi-Actor】12OpenGPTsの概要と使い方【OSS版のGPTs】13LangChain Evaluations【生成物の評価方法】14LangChain Hub15OpenAI Evalsとは？16LangChain Model I/Oとは？【Prompts・Language Models・Output Parsers】17LangChain Retrievalとは？【Document Loaders・Vector [...] Streamlit】23LangChainによる「Youtube動画を学習させる方法」24LangChainによる「特定のウェブページを学習させる方法」25LangChainによる「特定のPDFを学習させる方法」26LangChainによる「GitHubリポジトリを学習させる方法」27LangChainによる「演算機能を搭載する方法」28LangChainによる「ウェブ検索機能を搭載する方法」（Google API）29LangChainによる「ウェブ検索機能を搭載する方法」（Bing API）30LangChainによる「ウェブ検索機能を搭載する方法」（DuckDuckGo API）31LangChainによる「Pandasのデータフレームを操作する方法」32LangChainによる「SQL操作をする方法」33LangChainによる「文献参照をする方法」34最後に35【旧】LangChain Modelsとは？【LLMs・Chat Models・Text Embedding Models】36【旧】LangChain Promptとは？【Templates・Example [...] Selectors・Output Parsers】37【旧】LangChain Indexesとは？【Document Loaders・Text Splitters・Vectorstores】'},\n",
              " {'url': 'https://tech.nri-net.com/entry/creating_rags_for_multiple_data_sources_using_langgraph',\n",
              "  'content': \"- messages -> [AIMessage(content='野球の起源となった球技としては、イギリスの「タウンボール」が挙げられます。タウンボールはイギリス系移民によってアメリカに持ち込まれ、そこから変化していったと考えられています。多くの研究者が、この過程を経て野球が形成されたと見ています。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 242, 'total_tokens': 332, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-8a1dd045-cf16-4f8a-a377-58385e3c461c-0', usage_metadata={'input_tokens': 242, 'output_tokens': 90, 'total_tokens': 332, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})] - messages -> [AIMessage(content='パリオリンピックの男子バスケットボールで優勝した国はアメリカ合衆国です。決勝戦ではフランスを98対87で破り、5大会連続17度目の金メダルを獲得しました。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 230, 'total_tokens': 292, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-9e37f769-7c99-46d1-aaae-de1c2b3a0021-0', usage_metadata={'input_tokens': 230, 'output_tokens': 62, 'total_tokens': 292, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\"},\n",
              " {'url': 'https://www.youtube.com/watch?v=v3b4MEII-cc',\n",
              "  'content': 'LangChainをその場のノリで解説するゆるい勉強会です！ 今回は「LangGraphのチュートリアルを動かしながら解説」というテーマです。'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# State を定義\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Graph (StateGraph) のインスタンスを作成\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Chat model のインスタンスを作成\n",
        "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "\n",
        "# 使用できる Tool の情報を Chat model 渡す\n",
        "## 上で作成した Tool のリストをバインドする\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "# LLM を呼び出す Node を定義\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Node を Graph に追加\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "id": "VFhLPHBIoPpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e8aed2-aeb0-4e90-def7-9fda499a3a90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7c6d39a9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool で処理を実行する Node を追加する\n",
        "ここでは、LangGraph に予め用意されている `ToolNode` を使用する。  \n",
        "[ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode)"
      ],
      "metadata": {
        "id": "JfEBFzkK1Dpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# ToolNode のインスタンスを作成\n",
        "## 上で作成した Tool のリストを渡す, can be more than one\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "\n",
        "# Node を Graph に追加\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "id": "RGO8NfWZzlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15def232-26e9-4c3c-919e-b9c02ba56e68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7c6d39a9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "この Node のクラスは自分で定義することもできる。"
      ],
      "metadata": {
        "id": "66-mEvDpLN3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# from langchain_core.messages import ToolMessage\n",
        "\n",
        "# class BasicToolNode:\n",
        "#     \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
        "\n",
        "#     def __init__(self, tools: list) -> None:\n",
        "#         self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "#     def __call__(self, inputs: dict):\n",
        "#         if messages := inputs.get(\"messages\", []):\n",
        "#             message = messages[-1]\n",
        "#         else:\n",
        "#             raise ValueError(\"No message found in input\")\n",
        "#         outputs = []\n",
        "#         for tool_call in message.tool_calls:\n",
        "#             tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
        "#                 tool_call[\"args\"]\n",
        "#             )\n",
        "#             outputs.append(\n",
        "#                 ToolMessage(\n",
        "#                     content=json.dumps(tool_result),\n",
        "#                     name=tool_call[\"name\"],\n",
        "#                     tool_call_id=tool_call[\"id\"],\n",
        "#                 )\n",
        "#             )\n",
        "#         return {\"messages\": outputs}\n",
        "\n",
        "# tool_node = BasicToolNode(tools=[tool])\n",
        "# graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "id": "3wdyKkUNTaU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool を使うかどうか条件分岐する Edge を追加する\n",
        "ここでは、LangGraph にあらかじめ用意されている `tools_conditon` を使用する。  \n",
        "[tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/?#tools_condition)"
      ],
      "metadata": {
        "id": "C4wVuswe2lad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "# Edge を Graph に追加\n",
        "## Node \"chatbot\" の処理後に条件分岐を行う\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")"
      ],
      "metadata": {
        "id": "CJQgiy_X136L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a650406-db6a-44d8-9f07-42404aa1a462"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7c6d39a9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "この Edge のクラスは自分で定義することもできる。"
      ],
      "metadata": {
        "id": "NL4MaTrMlXWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from typing import Literal\n",
        "\n",
        "# def route_tools(\n",
        "#     state: State,\n",
        "# ) -> Literal[\"tools\", \"__end__\"]:\n",
        "#     \"\"\"Use in the conditional_edge to route to the ToolNode if the last message\n",
        "\n",
        "#     has tool calls. Otherwise, route to the end.\"\"\"\n",
        "#     if isinstance(state, list):\n",
        "#         ai_message = state[-1]\n",
        "#     elif messages := state.get(\"messages\", []):\n",
        "#         ai_message = messages[-1]\n",
        "#     else:\n",
        "#         raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "#     if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
        "#         return \"tools\"\n",
        "#     return \"__end__\"\n",
        "\n",
        "# # The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
        "# # it is fine directly responding. This conditional routing defines the main agent loop.\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"chatbot\",\n",
        "#     route_tools,\n",
        "#     # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
        "#     # It defaults to the identity function, but if you\n",
        "#     # want to use a node named something else apart from \"tools\",\n",
        "#     # You can update the value of the dictionary to something else\n",
        "#     # e.g., \"tools\": \"my_tools\"\n",
        "#     {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
        "# )\n",
        "# # Any time a tool is called, we return to the chatbot to decide the next step\n",
        "# graph_builder.add_edge(\"tools\", \"chatbot\")"
      ],
      "metadata": {
        "id": "ooRp8X2bUSL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tools → chatbot への Edge を追加\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "# エントリーポイントをセット\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "\n",
        "# Graph をコンパイル\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# end point auto set"
      ],
      "metadata": {
        "id": "9HPu1O_bUlH5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph を可視化"
      ],
      "metadata": {
        "id": "JLbUS7A4NF_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "yjxo_JyvUtLi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "5d8a9970-5a44-4939-de65-bdae84a92696"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph を実行"
      ],
      "metadata": {
        "id": "bTKLhx41NbLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"messages\": [(\"user\", \"LangGraph におけるノードとは何ですか。\")]})"
      ],
      "metadata": {
        "id": "yDp9qZildHNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4772ec5-89d5-4101-e3b3-dffdd34dbed3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='LangGraph におけるノードとは何ですか。', additional_kwargs={}, response_metadata={}, id='8879f59f-e2a2-49cc-be2a-eae2d7637494'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CYukC26o22OaQPlN6ySeifOy', 'function': {'arguments': '{\"query\":\"LangGraph ノード\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 92, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bf03fcb9-e260-45dc-b3d5-275ee2ef74c9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph ノード'}, 'id': 'call_CYukC26o22OaQPlN6ySeifOy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 92, 'output_tokens': 22, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='[{\"url\": \"https://langchain-ai.github.io/langgraph/concepts/low_level/\", \"content\": \"In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \\\\\"config\\\\\", containing optional configurable parameters (such as a thread_id).\\\\nSimilar to NetworkX, you add these nodes to a graph using the add_node method:\\\\n[](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-7-1)from langchain_core.runnables import RunnableConfig [...] By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State. To emphasize: Nodes and Edges are nothing more than Python functions - they can contain an LLM or just good ol\\' Python code.\\\\nIn short: nodes do the work. edges tell what to do next. [...] LangGraph\\'s underlying graph algorithm uses message passing to define a general program. When a Node completes its operation, it sends messages along one or more edges to other node(s). These recipient nodes then execute their functions, pass the resulting messages to the next set of nodes, and the process continues. Inspired by Google\\'s Pregel system, the program proceeds in discrete \\\\\"super-steps.\\\\\"\"}, {\"url\": \"https://zenn.dev/tomodo_ysys/articles/langgraph-basic-elements\", \"content\": \"node\\\\nnodeはgraph内における1つ1つの処理の塊を示します。\\\\n実態としてはstateを引数として受け取り、更新したstateを返す関数です。関数であればよいので、単純にテキスト生成するchainでもagentでもルールベースのロジックでもよいです。\\\\nたとえば、chatbotであれば以下のように定義できます。\\\\npython\\\\ndef chatbot(state: State):\\\\n    state[\\\\\"messages\\\\\"].append(llm_with_tools.invoke(state[\\\\\"messages\\\\\"]))\\\\n    return state\\\\nただし、LangGraphは親切なので、stateの中の更新したいキー、バリューだけでもよいです。\\\\npython\\\\ndef chatbot(state: State):\\\\n    return {\\\\\"messages\\\\\": [llm_with_tools.invoke(state[\\\\\"messages\\\\\"])]}\\\\nこれはすごく便利なのですが、最初に構造を理解する際にはかえってわかりづらいかもしれません。 [...] Quick Start Part2のGraph\\\\ngraphには大きくstate,node,edgeの3要素が含まれます。それぞれ詳しくは後述しますが、ざっくりいうと\\\\n\\\\n\\\\nstate: エージェントの状態を定義したもの（データ）です。上記のgraphの図には描画されていません。このgraphにinputとして与えられ、各処理のinput/outputとなりながら更新され、最終的にoutputされるものです。\\\\n\\\\n\\\\nnode: chatbotやtoolsなどgraphの中の各処理です。stateを受け取り、自分の処理によってstateを更新し、stateを返します。\\\\n\\\\n\\\\nedge: 各処理のつながりを定義するものです。最初はAノード、Aノードの次はBノード、Bノードのあとは終わり、などです。条件分岐も定義できます。 [...] ちなみにクイックスタートの中だとtoolsはToolNodeというもともとlangchainで定義されているノードを使っています。\\\\nhttps://github.com/langchain-ai/langgraph/blob/e3ca7bb3e9d34b09633852f4d08d55f6dcd4364b/libs/langgraph/langgraph/prebuilt/tool_node.py#L56\\\\npython\\\\n    tools_by_name = {tool.name: tool for tool in tools}\\\\n    def tool_node(state: dict):\\\\n        result = []\\\\n        for tool_call in state[\\\\\"messages\\\\\"][-1].tool_calls:\\\\n            tool = tools_by_name[tool_call[\\\\\"name\\\\\"]]\\\\n            observation = tool.invoke(tool_call[\\\\\"args\\\\\"])\"}, {\"url\": \"https://zenn.dev/pharmax/articles/8796b892eed183\", \"content\": \"| コンポーネント | 説明 |\\\\n| --- | --- |\\\\n| Graph | LangGraphの中核となる構成要素で、各NodeとEdgeの集合体です。 |\\\\n| State | ノード間の遷移の際に保持される情報で、各ノードが参照および更新します。 |\\\\n| Node | グラフ内の個々のステップや状態を表す要素で、特定のアクションやチェックポイントとして機能します。 |\\\\n| Edge | ノード間の接続を表し、遷移の条件やアクションを定義します。条件付きエッジなど、特定のロジックに基づいて遷移を制御できます。 |\\\\nGraph\\\\nGraphは、LangGraphの中核となるグラフ全体を管理するためのコンポーネントです。基本的な使い方としては、StateGraphというクラスを使い、後述するStateとセットで初期化します。\\\\n（StateGraphの宣言例）\\\\n```python\\\\nfrom typing_extensions import TypedDict\\\\nfrom langgraph.graph import StateGraph\\\\nStateを宣言 [...] from typing import Annotated\\\\nfrom typing_extensions import TypedDict\\\\nfrom langchain_core.runnables import RunnableConfig\\\\nfrom langgraph.graph import StateGraph\\\\nStateを宣言\\\\nclass State(TypedDict):\\\\n    value: str\\\\nNodeを宣言\\\\ndef node(state: State, config: RunnableConfig):\\\\n    return {\\\\\"value\\\\\": \\\\\"hoge\\\\\"}\\\\ngraph = StateGraph(State)\\\\nGraphにNodeを追加\\\\ngraph.add_node(\\\\\"node\\\\\", node)\\\\n```\\\\ngraphに対して add_node というメソッドを使用して、nodeを紐づけます。第一引数は、Nodeに対して任意のpath名を文字列で指定できます。\\\\nEdge [...] graph_builder.add_node(\\\\\"node\\\\\", node)\\\\ngraph_builder.add_node(\\\\\"node2\\\\\", node2)\\\\nNodeの関連をedgeに追加\\\\ngraph_builder.add_edge(\\\\\"node\\\\\", \\\\\"node2\\\\\")\\\\nGraphの始点を宣言\\\\ngraph_builder.set_entry_point(\\\\\"node\\\\\")\\\\nGraphの終点を宣言\\\\ngraph_builder.set_finish_point(\\\\\"node2\\\\\")\\\\n```\\\\nadd_edge(<from path>, <to path>)を使って、どのNodeから次のNodeへ処理が移るかを表現することができます。\\\\nまた、set_entry_point、set_finish_pointをつかってグラフの始点と終点を指定することができます。\\\\nGraphの基本的な作り方\\\\nここからはLangGraphのコンポーネントを使って、基本的なグラフを作成していきます。\\\\n単純なグラフ\\\\nまずは、次のような単純な経路のグラフを作成します。\"}, {\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph Studio for Desktop & Cloud  \\\\nWhat are my deployment options for LangGraph Platform?\\\\nWe currently have the following deployment options for LangGraph applications:  \\\\n\\u200dSelf-Hosted\\xa0Lite: A free (up to 1M nodes executed), limited version of LangGraph Platform that you can run locally or in a self-hosted manner. This version requires a LangSmith API key and logs all usage to LangSmith. Fewer features are available than in paid plans.\"}, {\"url\": \"https://book.st-hakky.com/data-science/langgraph-intro/\", \"content\": \"2024年6月18日に最終更新\\\\n前へ LangFlow とは次へ LangGraph+StreamlitでStreamling\\\\n資料請求 ---- Hakkyの案件事例や提供するソリューションを確認する\\\\nメールマガジン ------- データ・AIに関するHakky独自の考察を受け取る\\\\nお問い合わせ ------ AIプロダクトやデータ活用のお悩みをHakkyに無料相談する\\\\n\\\\nはじめに\\\\nLangGraph の全体像\\\\nノードの処理の解説\\\\nグラフの実行\\\\n参考文献\\\\n\\\\n\\\\n株式会社Hakky\\\\n〒160-0022 東京都新宿区新宿五丁目18番20号\\\\nルックハイツ新宿803号\\\\nHandbook\\\\n\\\\n業界から事例を探す\\\\n業務から事例を探す\\\\n導入目的・課題から事例を探す\\\\nBlogをみる\\\\nNewsをみる\\\\nウェビナーをみる\\\\n\\\\nService\\\\n\\\\nデータ活用支援\\\\n機械学習プロダクト開発支援\\\\nデータ基盤構築支援\\\\n\\\\nProduct\\\\n\\\\nFindVox\\\\naigleApp\\\\n\\\\nAbout Us\\\\n\\\\nCompany\\\\nStackshare\\\\n採用情報\\\\nニュース [...] このページの見出し\\\\n執筆者：Hakky社メンバー\\\\nLangGraphとは？サンプルコードをもとにわかりやすく解説！\\\\nはじめに\\u200b\\\\nこれまでの LangChain は一本の鎖のように A=>B=>C というように、処理が連続していて一方向にデータが流れていく構造でした。 LangGraph の登場によって簡単にサイクル（繰り返し循環する）を実装することができるようになりました。 LangChain についてはLangChain とは？各モジュールの機能と活用事例まとめやLangChain のエージェントについてで解説しています。\\\\nLangGraph の全体像\\u200b\\\\nそれでは公式のサンプルに沿って実装しながら解説していきます。 公式ではTavilyという検索ツールを使って、学習データにない情報を取得して質問に答えるというサンプルが紹介されています。 完全なコードは公式のサンプルを参照してください。\\\\n今回はこのような循環する二つのノードのグラフを作成します。 [...] ノードの処理の解説\\u200b\\\\n先ほどの例で追加した二つのノードがどのような実装をされているのか見ていきましょう。 まずは Action ノードの処理から解説します。\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/how-tos/tool-calling/\", \"content\": \"How to call tools using ToolNode¶\\\\nThis guide covers how to use LangGraph\\'s prebuilt ToolNode for tool calling.\\\\nToolNode is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls. It is designed to work well out-of-box with LangGraph\\'s prebuilt ReAct agent, but can also work with any StateGraph as long as its state has a messages key with an appropriate reducer (see MessagesState).\\\\nSetup¶ [...] Next, let\\'s see how to use ToolNode inside a LangGraph graph. Let\\'s set up a graph implementation of the ReAct agent. This agent takes some query as input, then repeatedly call tools until it has enough information to resolve the query. We\\'ll be using ToolNode and the Anthropic model with tools we just defined\\\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-1)from typing import Literal\"}, {\"url\": \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\", \"content\": \"Let’s walk through a simple example where we use LangGraph to classify user input as either a “greeting” or a “search” query and respond accordingly.\\\\nStep 1: Define the Graph State\\\\nFirst, we define the state structure for our graph. In this example, our state includes the user’s question, the classification of the question, and a response.\\\\nStep 2: Create the Graph\\\\nNext, we create a new instance of StateGraph with our GraphState structure.\\\\nStep 3: Define Nodes [...] LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph. Happy coding!\\\\n--\\\\n--\\\\n9\\\\nWritten by CPlog [...] We define nodes for classifying the input, handling greetings, and handling search queries.\\\\nStep 4: Add Nodes to the Graph\\\\nWe add our nodes to the graph and define the flow using edges and conditional edges.\\\\nStep 5: Set Entry and End Points\\\\nWe set the entry point for our graph and define the end points.\\\\nStep 6: Compile and Run the Graph\\\\nFinally, we compile our graph and run it with some input.\\\\nCommon Confusions\\\\nConclusion\"}, {\"url\": \"https://blog.langchain.dev/langgraph/\", \"content\": \"graph.add_node(\\\\\"tools\\\\\", tool_executor)\\\\nThere is also a special END node that is used to represent the end of the graph. It is important that your cycles be able to end eventually!\\\\nfrom langgraph.graph import END\\\\nEdges\\\\nAfter adding nodes, you can then add edges to create the graph. There are a few types of edges.\\\\nThe Starting Edge [...] Published Time: 2024-01-17T17:46:54.000Z\\\\nLangGraph\\\\nSkip to content\\\\n\\\\n\\\\nCase Studies\\\\nIn the Loop\\\\nLangChain\\\\nDocs\\\\nChangelog\\\\n\\\\nSign in Subscribe\\\\n\\\\nLangGraph\\\\nBy LangChain 7 min read Jan 17, 2024\\\\nTL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.\\\\n\\\\nPython Repo\\\\nPython YouTube Playlist\\\\nJS Repo [...] After creating a StateGraph, you then add nodes with graph.add_node(name, value) syntax. The name parameter should be a string that we will use to refer to the node when adding edges. The value parameter should be either a function or LCEL runnable that will be called. This function/LCEL should accept a dictionary in the same form as the State object as input, and output a dictionary with keys of the State object to update.\\\\nSee an example in pseudocode below.\\\\ngraph.add_node(\\\\\"model\\\\\", model)\"}]', name='tavily_search_results_json', id='7ed037b6-9473-41fb-adb5-cbc1c39178da', tool_call_id='call_CYukC26o22OaQPlN6ySeifOy', artifact={'query': 'LangGraph ノード', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/', 'title': 'LangGraph Glossary - GitHub Pages', 'content': 'In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id).\\nSimilar to NetworkX, you add these nodes to a graph using the add_node method:\\n[](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-7-1)from langchain_core.runnables import RunnableConfig [...] By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State. To emphasize: Nodes and Edges are nothing more than Python functions - they can contain an LLM or just good ol\\' Python code.\\nIn short: nodes do the work. edges tell what to do next. [...] LangGraph\\'s underlying graph algorithm uses message passing to define a general program. When a Node completes its operation, it sends messages along one or more edges to other node(s). These recipient nodes then execute their functions, pass the resulting messages to the next set of nodes, and the process continues. Inspired by Google\\'s Pregel system, the program proceeds in discrete \"super-steps.\"', 'score': 0.7740387693371212, 'raw_content': None}, {'url': 'https://zenn.dev/tomodo_ysys/articles/langgraph-basic-elements', 'title': 'LangGraphの基本的な要素を日本語でわかりやすくまとめる - Zenn', 'content': 'node\\nnodeはgraph内における1つ1つの処理の塊を示します。\\n実態としてはstateを引数として受け取り、更新したstateを返す関数です。関数であればよいので、単純にテキスト生成するchainでもagentでもルールベースのロジックでもよいです。\\nたとえば、chatbotであれば以下のように定義できます。\\npython\\ndef chatbot(state: State):\\n    state[\"messages\"].append(llm_with_tools.invoke(state[\"messages\"]))\\n    return state\\nただし、LangGraphは親切なので、stateの中の更新したいキー、バリューだけでもよいです。\\npython\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\nこれはすごく便利なのですが、最初に構造を理解する際にはかえってわかりづらいかもしれません。 [...] Quick Start Part2のGraph\\ngraphには大きくstate,node,edgeの3要素が含まれます。それぞれ詳しくは後述しますが、ざっくりいうと\\n\\n\\nstate: エージェントの状態を定義したもの（データ）です。上記のgraphの図には描画されていません。このgraphにinputとして与えられ、各処理のinput/outputとなりながら更新され、最終的にoutputされるものです。\\n\\n\\nnode: chatbotやtoolsなどgraphの中の各処理です。stateを受け取り、自分の処理によってstateを更新し、stateを返します。\\n\\n\\nedge: 各処理のつながりを定義するものです。最初はAノード、Aノードの次はBノード、Bノードのあとは終わり、などです。条件分岐も定義できます。 [...] ちなみにクイックスタートの中だとtoolsはToolNodeというもともとlangchainで定義されているノードを使っています。\\nhttps://github.com/langchain-ai/langgraph/blob/e3ca7bb3e9d34b09633852f4d08d55f6dcd4364b/libs/langgraph/langgraph/prebuilt/tool_node.py#L56\\npython\\n    tools_by_name = {tool.name: tool for tool in tools}\\n    def tool_node(state: dict):\\n        result = []\\n        for tool_call in state[\"messages\"][-1].tool_calls:\\n            tool = tools_by_name[tool_call[\"name\"]]\\n            observation = tool.invoke(tool_call[\"args\"])', 'score': 0.7606992332386363, 'raw_content': None}, {'url': 'https://zenn.dev/pharmax/articles/8796b892eed183', 'title': 'LangGraphの基本的な使い方 - Zenn', 'content': '| コンポーネント | 説明 |\\n| --- | --- |\\n| Graph | LangGraphの中核となる構成要素で、各NodeとEdgeの集合体です。 |\\n| State | ノード間の遷移の際に保持される情報で、各ノードが参照および更新します。 |\\n| Node | グラフ内の個々のステップや状態を表す要素で、特定のアクションやチェックポイントとして機能します。 |\\n| Edge | ノード間の接続を表し、遷移の条件やアクションを定義します。条件付きエッジなど、特定のロジックに基づいて遷移を制御できます。 |\\nGraph\\nGraphは、LangGraphの中核となるグラフ全体を管理するためのコンポーネントです。基本的な使い方としては、StateGraphというクラスを使い、後述するStateとセットで初期化します。\\n（StateGraphの宣言例）\\n```python\\nfrom typing_extensions import TypedDict\\nfrom langgraph.graph import StateGraph\\nStateを宣言 [...] from typing import Annotated\\nfrom typing_extensions import TypedDict\\nfrom langchain_core.runnables import RunnableConfig\\nfrom langgraph.graph import StateGraph\\nStateを宣言\\nclass State(TypedDict):\\n    value: str\\nNodeを宣言\\ndef node(state: State, config: RunnableConfig):\\n    return {\"value\": \"hoge\"}\\ngraph = StateGraph(State)\\nGraphにNodeを追加\\ngraph.add_node(\"node\", node)\\n```\\ngraphに対して add_node というメソッドを使用して、nodeを紐づけます。第一引数は、Nodeに対して任意のpath名を文字列で指定できます。\\nEdge [...] graph_builder.add_node(\"node\", node)\\ngraph_builder.add_node(\"node2\", node2)\\nNodeの関連をedgeに追加\\ngraph_builder.add_edge(\"node\", \"node2\")\\nGraphの始点を宣言\\ngraph_builder.set_entry_point(\"node\")\\nGraphの終点を宣言\\ngraph_builder.set_finish_point(\"node2\")\\n```\\nadd_edge(<from path>, <to path>)を使って、どのNodeから次のNodeへ処理が移るかを表現することができます。\\nまた、set_entry_point、set_finish_pointをつかってグラフの始点と終点を指定することができます。\\nGraphの基本的な作り方\\nここからはLangGraphのコンポーネントを使って、基本的なグラフを作成していきます。\\n単純なグラフ\\nまずは、次のような単純な経路のグラフを作成します。', 'score': 0.7056852179924241, 'raw_content': None}, {'url': 'https://www.langchain.com/langgraph', 'title': 'LangGraph - LangChain', 'content': 'LangGraph Studio for Desktop & Cloud  \\nWhat are my deployment options for LangGraph Platform?\\nWe currently have the following deployment options for LangGraph applications:  \\n\\u200dSelf-Hosted\\xa0Lite: A free (up to 1M nodes executed), limited version of LangGraph Platform that you can run locally or in a self-hosted manner. This version requires a LangSmith API key and logs all usage to LangSmith. Fewer features are available than in paid plans.', 'score': 0.6007724863636363, 'raw_content': None}, {'url': 'https://book.st-hakky.com/data-science/langgraph-intro/', 'title': 'LangGraphとは？サンプルコードをもとにわかりやすく解説！', 'content': '2024年6月18日に最終更新\\n前へ LangFlow とは次へ LangGraph+StreamlitでStreamling\\n資料請求 ---- Hakkyの案件事例や提供するソリューションを確認する\\nメールマガジン ------- データ・AIに関するHakky独自の考察を受け取る\\nお問い合わせ ------ AIプロダクトやデータ活用のお悩みをHakkyに無料相談する\\n\\nはじめに\\nLangGraph の全体像\\nノードの処理の解説\\nグラフの実行\\n参考文献\\n\\n\\n株式会社Hakky\\n〒160-0022 東京都新宿区新宿五丁目18番20号\\nルックハイツ新宿803号\\nHandbook\\n\\n業界から事例を探す\\n業務から事例を探す\\n導入目的・課題から事例を探す\\nBlogをみる\\nNewsをみる\\nウェビナーをみる\\n\\nService\\n\\nデータ活用支援\\n機械学習プロダクト開発支援\\nデータ基盤構築支援\\n\\nProduct\\n\\nFindVox\\naigleApp\\n\\nAbout Us\\n\\nCompany\\nStackshare\\n採用情報\\nニュース [...] このページの見出し\\n執筆者：Hakky社メンバー\\nLangGraphとは？サンプルコードをもとにわかりやすく解説！\\nはじめに\\u200b\\nこれまでの LangChain は一本の鎖のように A=>B=>C というように、処理が連続していて一方向にデータが流れていく構造でした。 LangGraph の登場によって簡単にサイクル（繰り返し循環する）を実装することができるようになりました。 LangChain についてはLangChain とは？各モジュールの機能と活用事例まとめやLangChain のエージェントについてで解説しています。\\nLangGraph の全体像\\u200b\\nそれでは公式のサンプルに沿って実装しながら解説していきます。 公式ではTavilyという検索ツールを使って、学習データにない情報を取得して質問に答えるというサンプルが紹介されています。 完全なコードは公式のサンプルを参照してください。\\n今回はこのような循環する二つのノードのグラフを作成します。 [...] ノードの処理の解説\\u200b\\n先ほどの例で追加した二つのノードがどのような実装をされているのか見ていきましょう。 まずは Action ノードの処理から解説します。', 'score': 0.593542584034091, 'raw_content': None}, {'url': 'https://langchain-ai.github.io/langgraph/how-tos/tool-calling/', 'title': 'How to call tools using ToolNode - GitHub Pages', 'content': \"How to call tools using ToolNode¶\\nThis guide covers how to use LangGraph's prebuilt ToolNode for tool calling.\\nToolNode is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls. It is designed to work well out-of-box with LangGraph's prebuilt ReAct agent, but can also work with any StateGraph as long as its state has a messages key with an appropriate reducer (see MessagesState).\\nSetup¶ [...] Next, let's see how to use ToolNode inside a LangGraph graph. Let's set up a graph implementation of the ReAct agent. This agent takes some query as input, then repeatedly call tools until it has enough information to resolve the query. We'll be using ToolNode and the Anthropic model with tools we just defined\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-1)from typing import Literal\", 'score': 0.5926594899147727, 'raw_content': None}, {'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141', 'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\", 'content': 'Let’s walk through a simple example where we use LangGraph to classify user input as either a “greeting” or a “search” query and respond accordingly.\\nStep 1: Define the Graph State\\nFirst, we define the state structure for our graph. In this example, our state includes the user’s question, the classification of the question, and a response.\\nStep 2: Create the Graph\\nNext, we create a new instance of StateGraph with our GraphState structure.\\nStep 3: Define Nodes [...] LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph. Happy coding!\\n--\\n--\\n9\\nWritten by CPlog [...] We define nodes for classifying the input, handling greetings, and handling search queries.\\nStep 4: Add Nodes to the Graph\\nWe add our nodes to the graph and define the flow using edges and conditional edges.\\nStep 5: Set Entry and End Points\\nWe set the entry point for our graph and define the end points.\\nStep 6: Compile and Run the Graph\\nFinally, we compile our graph and run it with some input.\\nCommon Confusions\\nConclusion', 'score': 0.5481558061837122, 'raw_content': None}, {'url': 'https://blog.langchain.dev/langgraph/', 'title': 'LangGraph - LangChain Blog', 'content': 'graph.add_node(\"tools\", tool_executor)\\nThere is also a special END node that is used to represent the end of the graph. It is important that your cycles be able to end eventually!\\nfrom langgraph.graph import END\\nEdges\\nAfter adding nodes, you can then add edges to create the graph. There are a few types of edges.\\nThe Starting Edge [...] Published Time: 2024-01-17T17:46:54.000Z\\nLangGraph\\nSkip to content\\n\\n\\nCase Studies\\nIn the Loop\\nLangChain\\nDocs\\nChangelog\\n\\nSign in Subscribe\\n\\nLangGraph\\nBy LangChain 7 min read Jan 17, 2024\\nTL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes.\\n\\nPython Repo\\nPython YouTube Playlist\\nJS Repo [...] After creating a StateGraph, you then add nodes with graph.add_node(name, value) syntax. The name parameter should be a string that we will use to refer to the node when adding edges. The value parameter should be either a function or LCEL runnable that will be called. This function/LCEL should accept a dictionary in the same form as the State object as input, and output a dictionary with keys of the State object to update.\\nSee an example in pseudocode below.\\ngraph.add_node(\"model\", model)', 'score': 0.5309152498106061, 'raw_content': None}], 'response_time': 1.69}),\n",
              "  AIMessage(content='LangGraphにおけるノード（Node）は、グラフ内の個々の処理の単位を表します。具体的には、ノードはPythonの関数（同期または非同期）であり、最初の引数として状態（state）を受け取り、オプションで2番目の引数として設定（config）を受け取ることができます。この関数は、状態を更新し、更新された状態を返します。\\n\\nノードは、以下のような役割を果たします：\\n\\n1. **処理の実行**: ノードは特定のアクションを実行し、状態を変更します。例えば、チャットボットのノードは、ユーザーからのメッセージを受け取り、応答を生成して状態を更新します。\\n\\n2. **状態の管理**: 各ノードは、他のノードと連携して状態を管理し、次のノードにメッセージを送信します。これにより、ノード間での情報の流れが確立されます。\\n\\n3. **グラフの構成要素**: ノードは、LangGraphのグラフを構成する重要な要素であり、エッジ（Edge）と組み合わせて複雑なワークフローを作成します。\\n\\nノードは、状態を受け取り、処理を行い、結果として新しい状態を返す関数であるため、非常に柔軟であり、さまざまな処理を実装することができます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 356, 'prompt_tokens': 3314, 'total_tokens': 3670, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3200}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None}, id='run-bfca7110-3841-4e06-b3b4-dd646dd34ca0-0', usage_metadata={'input_tokens': 3314, 'output_tokens': 356, 'total_tokens': 3670, 'input_token_details': {'audio': 0, 'cache_read': 3200}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event = graph.invoke({\"messages\": [(\"user\", \"LangGraph におけるノードとは何ですか。\")]})\n",
        "print(event[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "pmU6nSyBNWDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c729dc9-2ecc-4c4f-9e33-2ddfaeb644fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraphにおけるノード（Node）は、グラフ内の個々の処理の単位を表します。具体的には、ノードはPythonの関数（同期または非同期）であり、最初の引数として状態（state）を受け取り、オプションで2番目の引数として設定（config）を受け取ることができます。この関数は、状態を更新し、更新された状態を返します。\n",
            "\n",
            "ノードは、以下のような役割を果たします：\n",
            "\n",
            "1. **処理の実行**: ノードは特定のアクションを実行し、状態を変更します。例えば、チャットボットのノードは、ユーザーからのメッセージを受け取り、応答を生成することができます。\n",
            "\n",
            "2. **状態の管理**: 各ノードは、他のノードと連携して状態を管理し、次のノードにメッセージを送信します。これにより、ノード間での情報の流れが確立されます。\n",
            "\n",
            "3. **グラフの構成要素**: ノードは、LangGraphのグラフを構成する重要な要素であり、エッジ（Edge）と組み合わせて複雑なワークフローを作成することができます。\n",
            "\n",
            "ノードは、状態を受け取り、処理を行い、結果を返すというシンプルな構造を持っているため、さまざまな処理を柔軟に組み合わせることが可能です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "インタラクティブに実行"
      ],
      "metadata": {
        "id": "A1nk_2jWPDz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    response = graph.invoke({\"messages\": [(\"user\", user_input)]})\n",
        "    print(\"Assistant:\", response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "RgAOecx-lcNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e78fb6-1db5-4fcf-e382-62dab6b21c36"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: what's scorpio luck today\n",
            "Assistant: Today, October 3, 2023, Scorpio's luck is as follows:\n",
            "\n",
            "- **Love Fortune**: 78\n",
            "- **Fortune Index**: 68\n",
            "- **Lucky Color**: Light yellow, orange, or blue\n",
            "- **Lucky Number**: 8\n",
            "\n",
            "For more details, you can check the full horoscope [here](https://en.mofalulu.com/Scorpio/luckday_20231003.html).\n",
            "User: today is 2025/3/19\n",
            "Assistant: Here are some notable news highlights from March 19, 2025:\n",
            "\n",
            "1. **Bank of Japan Policy**: The Bank of Japan has decided to keep its policy rate unchanged as it assesses the impact of tariffs imposed by former President Trump. [Read more here](https://english.kyodonews.net/news/2025/03/b8fc3ce9e3ec-kyodo-news-digest-march-19-2025--1-.html).\n",
            "\n",
            "2. **Massachusetts Legislative Visits**: Massachusetts legislators have visited Canadian renewable power operations, highlighting ongoing discussions about energy and health care systems in the state. [More details here](https://www.statehousenews.com/news/schedule/daily-advances---wednesday-march-19-2025/article_b5731bde-00ea-11f0-bf90-9f20bd2a9a6f.html?utm_source=statehousenews.com&utm_campaign=%2Fnewsletter%2Foptimize%2Fschedule%2F%3F-dc%3D1742340629&utm_medium=email&utm_content=read%20more).\n",
            "\n",
            "3. **Weather Update**: The weather in Bengaluru is starting warm at 22.26 °C, with forecasts indicating a mild and breezy day before potential storms in the evening. [Check the weather forecast here](https://www.hindustantimes.com/astrology/horoscope/horoscope-today-live-updates-march-19-2025-101742327437064.html).\n",
            "\n",
            "4. **Education Funding Changes**: The USDA's $660 million Local Food for Schools program, initiated under President Biden in 2021, has been canceled for 2025. [Learn more about this change](https://www.edweek.org/education/briefly-stated-march-19-2025/2025/03).\n",
            "\n",
            "5. **PBS News Hour**: A full episode of PBS News Hour aired on this date, covering various current events. [Watch the episode here](https://www.gpb.org/television/show/pbs-news-hour/season/2025/march-19-2025-pbs-news-hour-full-episode).\n",
            "\n",
            "These articles provide a snapshot of significant events and updates from today.\n",
            "User: today is 2025/3/19. luck of scorpio\n",
            "Assistant: Here is the daily horoscope for Scorpio on March 19, 2025:\n",
            "\n",
            "1. **General Overview**: Today, you may feel a strong urge to rebel against the norm, especially with the Moon in Scorpio opposing Uranus. This could lead to a desire for change and a fresh perspective on your life.\n",
            "\n",
            "2. **Personal Relationships**: Closeness with family will increase, and personal relationships are likely to strengthen. For married couples, this is a good time to consider starting a family.\n",
            "\n",
            "3. **Work and Career**: You have a backlog of work to tackle, so it's important to clear your mind of distractions. Your focus will increase, and your managerial efforts will be swift. Business matters are gaining momentum, and your work performance will meet expectations.\n",
            "\n",
            "4. **Social Life**: Friendships will deepen, and you will find yourself focusing on important tasks while increasing cooperation with others.\n",
            "\n",
            "5. **Advice**: Keep life's lessons close to heart, as they will guide you toward making a meaningful impact on society.\n",
            "\n",
            "For more detailed insights, you can check out the full horoscopes from sources like [India Today](https://www.indiatoday.in/horoscopes/story/horoscope-today-march-19-2025-aries-taurus-gemini-cancer-leo-virgo-libra-scorpio-sagittarius-capricorn-aquarius-pisces-2695279-2025-03-19) or [Indian Express](https://indianexpress.com/article/horoscope/scorpio-horoscope-today-19-march-2025-daily-astrology-prediction-for-scorpio-career-finance-money-love-9891713/).\n",
            "User: bye\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### まとめたコード"
      ],
      "metadata": {
        "id": "KyHCdT3gPRAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "tool = TavilySearchResults(max_results=5)\n",
        "tools = [tool]\n",
        "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.set_entry_point(\"chatbot\")\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "user_input = \"LangGraph におけるノードとは何ですか。\"\n",
        "\n",
        "response = graph.invoke({\"messages\": [(\"user\", user_input)]})\n",
        "print(\"Answer:\", response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "v4-6WZrL6V1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bac0ec-0e26-491b-ce0e-90c6acfc5e21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: LangGraphにおけるノードは、グラフ内の個々の処理を表す要素であり、通常はPythonの関数（同期または非同期）です。ノードは、最初の引数として状態（state）を受け取り、オプションで2番目の引数として設定（config）を受け取ります。この設定には、スレッドIDなどのオプションのパラメータが含まれることがあります。\n",
            "\n",
            "ノードは、状態を受け取り、その状態を更新して返す役割を果たします。例えば、チャットボットのノードは、受け取ったメッセージを処理し、新しいメッセージを状態に追加することができます。ノードは、他のノードとの接続を定義するエッジを介して相互作用し、メッセージを送信して次のノードを実行させることができます。\n",
            "\n",
            "要約すると、LangGraphのノードは、特定のアクションや処理を実行するための関数であり、状態を管理し、他のノードとの連携を通じて複雑なワークフローを構築するための基本的な構成要素です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"こんにちはの英語は？\"\n",
        "\n",
        "response = graph.invoke({\"messages\": [(\"user\", user_input)]})\n",
        "print(\"Answer:\", response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CxcGd08QnGC",
        "outputId": "7011c60d-ec21-4bbc-c4bb-6bdc0ab4675a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: こんにちはの英語は「Hello」です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: チャットボットに会話履歴を追加する\n",
        "---"
      ],
      "metadata": {
        "id": "T7gNKZCQvy-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpointer\n",
        "* ここでは、インメモリに履歴データを保存する `MemorySaver` を使用する。\n",
        "* データベースにデータを保存する場合は、`SqliteSaver` や `PostgresSaver` などを利用できる。\n",
        "  \n",
        "[MemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#memorysaver)"
      ],
      "metadata": {
        "id": "Z71eDDX2S2Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "KTbLPjU5xp8E"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "# State を定義\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Graph のインスタンスを作成\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Tool の用意\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "\n",
        "# Chat model のインスタンスを作成\n",
        "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "\n",
        "# Chat model に Tool の情報を渡す\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "# Node と Edge の追加\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        ")\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.set_entry_point(\"chatbot\")"
      ],
      "metadata": {
        "id": "vEX6DZY0xwZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb7617e-0dc1-4ced-9d5d-d3270458e7d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7e7c6d20a6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpointer を指定して Graph をコンパイル"
      ],
      "metadata": {
        "id": "C6JUiemqUBZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "tl7lU_wd9BCE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph を可視化"
      ],
      "metadata": {
        "id": "bpIXVN6vUU8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "muqPUoBt8r7s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "696b4657-e203-4391-e992-071ba2bc68b2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph を実行"
      ],
      "metadata": {
        "id": "Llw_y07hUfov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"a678\"}}"
      ],
      "metadata": {
        "id": "GznIGkUF856-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    response = graph.invoke({\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\")\n",
        "    print(\"Assistant:\", response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "irZeJr7Z-NdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf255dae-b5fe-4536-94f8-08ed824e6148"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: what is the luck of scorpio horoscope on 2025/3/21.\n",
            "Assistant: On March 21, 2025, Scorpio will experience a significant influence from Pluto, enhancing their ability to transform and reinvent various aspects of their life. This period is marked by opportunities for personal growth and change.\n",
            "\n",
            "Additionally, the weekly horoscope for Scorpio from March 16 to 22, 2025, suggests that it is a good time to take on crucial tasks at work, which could lead to favorable outcomes in terms of health and wealth.\n",
            "\n",
            "For more detailed insights, you can check the full horoscopes [here](https://gosta.media/en/horoscope-2025/horoscope-for-21-march-2025-for-all-zodiac-signs/) and [here](https://www.hindustantimes.com/astrology/horoscope/weekly-horoscope-scorpio-march-16-22-2025-predicts-good-health-and-wealth-101742042819789.html).\n",
            "User: how about money luck\n",
            "Assistant: On March 21, 2025, Scorpio's financial outlook will be characterized by a mix of opportunities and the need for cautious rebalancing. The early part of the month may present various financial opportunities, but it's essential for Scorpios to remain adaptable and open-minded to navigate potential challenges.\n",
            "\n",
            "For a more detailed analysis, you can refer to the full predictions [here](https://timesofindia.indiatimes.com/astrology/horoscope/march-2025-scorpio-predictions-love-career-and-finance-predictions/articleshow/118626855.cms) and [here](https://www.hindustantimes.com/astrology/horoscope/scorpio-monthly-horoscope-for-march-2025-predicts-a-mix-of-opportunities-101740751809546.html).\n",
            "User: how about today.\n",
            "Assistant: Today, March 21, 2024, Scorpio's horoscope indicates a need for caution, especially with paperwork. It's a day where being meticulous can help avoid potential issues. \n",
            "\n",
            "In terms of money, the horoscope suggests that relationships may improve, which could positively impact financial dealings. For more detailed insights into your daily horoscope, you can check the full predictions [here](https://www.mensxp.com/astrology/horoscope/157475-daily-horoscope-for-all-zodiac-signs-for-21-march-2024.html) and [here](https://www.indiatoday.in/horoscopes/scorpio/story/scorpio-horoscope-today-daily-for-21-march-2024-relationships-will-improve-2517440-2024-03-21).\n",
            "User: quit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: LangGraph Adaptive RAG\n",
        "---\n",
        "https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/"
      ],
      "metadata": {
        "id": "pQayogTccT-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index と Retiever を作成する\n",
        "*  Documentloader には `WebBaseLoader` を使用\n",
        "*  Text Splitter には `RecursiveCharacterTextSplitter` を使用\n",
        "*  Embeddings model には `OpenAIEmbeddings` を使用\n",
        "*  Vector store には `Chroma` を使用"
      ],
      "metadata": {
        "id": "INWGcoHEcmM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Embedding model を用意\n",
        "embd = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
        "\n",
        "# RAG 用にロードする Web サイトの URL を指定\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "# ドキュメント (Web サイト) をロード\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# ドキュメントをチャンクに分割\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=500, chunk_overlap=100\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Vector store と Retriever を作成\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=embd,\n",
        ")\n",
        "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 10})"
      ],
      "metadata": {
        "id": "5ooCHfG_4--6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60a16d8-e6f1-4983-cd4d-59fffb415f4a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM による各種の Chain を作成する"
      ],
      "metadata": {
        "id": "GAAMvtFDe6ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### question_router\n",
        "ユーザーの入力について、Vector store に問い合わせるか Web 検索するか決定する"
      ],
      "metadata": {
        "id": "14H3uuQFrLPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# Data model\n",
        "## ユーザークエリを最適なデータソースにルーティングするためのモデルを定義している。\n",
        "## このモデルには、datasource という必須の属性があり、その値は \"vectorstore\" または \"web_search\" のいずれかでなければならない。\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
        "\n",
        "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
        "        ...,\n",
        "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
        "    )\n",
        "\n",
        "\n",
        "# Chat model を用意\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "## Chat model に対して出力する形式を指定\n",
        "## https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.openai.ChatOpenAI.html#langchain_community.chat_models.openai.ChatOpenAI.with_structured_output\n",
        "structured_llm_router = model.with_structured_output(RouteQuery)\n",
        "\n",
        "# Prompt template を作成\n",
        "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
        "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
        "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "# Chain を定義\n",
        "## この Chain はユーザーのクエリに対して、`datasource` の値として `vectorstore` か `web_search` を返す\n",
        "question_router = route_prompt | structured_llm_router"
      ],
      "metadata": {
        "id": "1eYO464OeR_1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作を確認"
      ],
      "metadata": {
        "id": "uo4mlI-dOjGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    question_router.invoke(\n",
        "        {\"question\": \"明日の東京の天気予報は何ですか。\"}\n",
        "    )\n",
        ")\n",
        "print(question_router.invoke({\"question\": \"Agent の Memory とは何ですか。\"}))"
      ],
      "metadata": {
        "id": "0OCMmA4FOboi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd0b6dd-bb75-485c-875a-0708ca22ee3a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='web_search'\n",
            "datasource='vectorstore'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### retrieval_grader\n",
        "Retriever が取得したドキュメントがユーザーの入力に対して関連のある適切なものか判定して \"yes\" か \"no\" を返す"
      ],
      "metadata": {
        "id": "Hc3zHFMhryJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Chat model を用意\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt template を作成\n",
        "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain を定義\n",
        "retrieval_grader = grade_prompt | structured_llm_grader"
      ],
      "metadata": {
        "id": "Njat1uCHivpQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作を確認"
      ],
      "metadata": {
        "id": "R1YemhosO-yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"agent memory\"\n",
        "docs = retriever.invoke(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
        "len(docs)"
      ],
      "metadata": {
        "id": "cUmnRbYPO-OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e37f52-86ae-4af0-ce15-631dc5219dc8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"fish memory\"\n",
        "docs = retriever.invoke(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azw84RGiUR-w",
        "outputId": "d5c0a3f5-b8d5-4327-8ee9-b16b10beb0a2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='no'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rag_chain\n",
        "Retriever または Web 検索 Tool によって取得したドキュメントを使用して、ユーザーの入力に対する回答を生成する"
      ],
      "metadata": {
        "id": "aPeqOP4gt2kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Prompt を用意\n",
        "## https://smith.langchain.com/hub/rlm/rag-prompt?organizationId=5416e3b5-a584-5319-ad04-ae41aaac8e2b\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# Chat model を用意\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "# Post-processing\n",
        "# def format_docs(docs):\n",
        "#     return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt | model | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "hDuoXsQzt5kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作を確認"
      ],
      "metadata": {
        "id": "61Piqb5TPW1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ],
      "metadata": {
        "id": "oqMf9DrLPaWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hallucination_grader\n",
        "`rag_chain` による回答がグラウンディングされている (ハルシネーションでない) ことを判定して `yes` か `no` を返す"
      ],
      "metadata": {
        "id": "A7UNzsUo0Sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data model\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Chat model を用意\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm_grader = model.with_structured_output(GradeHallucinations)\n",
        "\n",
        "# Prompt template を作成\n",
        "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain を定義\n",
        "hallucination_grader = hallucination_prompt | structured_llm_grader"
      ],
      "metadata": {
        "id": "ztS3TpaLv7O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作を確認"
      ],
      "metadata": {
        "id": "d6sr3aU_RLgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
      ],
      "metadata": {
        "id": "T-DtDxU4RKOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### answer_grader\n",
        "`rag_chain` による回答がユーザーに入力に対して適正である (関連している/解決している) ことを判定して `yes` か `no` を返す"
      ],
      "metadata": {
        "id": "hVqI3TRM1toD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data model\n",
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Chat model を用意\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm_grader = model.with_structured_output(GradeAnswer)\n",
        "\n",
        "# Prompt template の作成\n",
        "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
        "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
        "answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain を定義\n",
        "answer_grader = answer_prompt | structured_llm_grader"
      ],
      "metadata": {
        "id": "5mDfZIdI1YGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作を確認"
      ],
      "metadata": {
        "id": "RjJ40c8kRyAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_grader.invoke({\"question\": question, \"generation\": generation})"
      ],
      "metadata": {
        "id": "3iwwmnWaRw_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### question_rewriter\n",
        "`retrieval_grader` または `answer_grader` で `no` と判定された場合、適切な回答を得やすいようにユーザーの入力を書き直す"
      ],
      "metadata": {
        "id": "0cEw4mn85Gg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat model を用意\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Prompt template を作成\n",
        "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain を定義\n",
        "question_rewriter = re_write_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "T_TsDw-w5y_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "動作を確認"
      ],
      "metadata": {
        "id": "vu19mLXESQk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_rewriter.invoke({\"question\": question})"
      ],
      "metadata": {
        "id": "1c9yYotpSPaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web 検索のための Tool を用意する"
      ],
      "metadata": {
        "id": "gyDcpqJq6n5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(max_results=5)"
      ],
      "metadata": {
        "id": "TrEwDqL-6A3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State を定義する"
      ],
      "metadata": {
        "id": "ygP8OZlo8MPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[str]"
      ],
      "metadata": {
        "id": "F5AkBABC7A29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph のコンポーネントを定義する\n",
        "ここまでに作った、Retriever、各種の Chain、Tool を使って、グラフにノードやエッジとして追加するための関数を定義していく"
      ],
      "metadata": {
        "id": "Vxkj3ACT8rhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "### Node ###\n",
        "\n",
        "# Retriever を実行する関数\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "# 最終的に回答の生成を実行する関数\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # RAG generation\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "# Retriever によって取得されたドキュメントを評価する関数\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            # retriever が取得したドキュメントがユーザーの入力に関連性があれば、filtered_docs に追加する\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            # ドキュメントに関連性がなければ捨てる\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"question\": question}\n",
        "\n",
        "\n",
        "# ユーザーの質問を書き直す関数\n",
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "# Web 検索を実行する関数\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "\n",
        "    return {\"documents\": web_results, \"question\": question}\n",
        "\n",
        "\n",
        "### Edge ###\n",
        "\n",
        "# Vectore store の検索か Web 検索かを判定する関数\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to web search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "\n",
        "    # question_router による判定の結果を返す\n",
        "    if source.datasource == \"web_search\":\n",
        "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
        "        return \"web_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\"\n",
        "\n",
        "\n",
        "# 最終的な回答の生成を行うか判定する関数\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    state[\"question\"]\n",
        "    filtered_documents = state[\"documents\"]\n",
        "\n",
        "\n",
        "    if not filtered_documents:\n",
        "        # grade_documents ですべてのドキュメントが関連性なしと判定された場合\n",
        "        print(\n",
        "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "        )\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # grade_documents で関連性があると判定されたドキュメントがある場合\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "# 生成された回答が適切かを判定する関数\n",
        "def grade_generation_v_documents_and_question(state):\n",
        "    \"\"\"\n",
        "    Determines whether the generation is grounded in the document and answers question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK HALLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    # Generate の回答がハルシネーションでないことを判定する\n",
        "    score = hallucination_grader.invoke(\n",
        "        {\"documents\": documents, \"generation\": generation}\n",
        "    )\n",
        "    grade = score.binary_score\n",
        "\n",
        "    # 回答がハルシネーションでなかった場合、回答が適正であることを判定する\n",
        "    if grade == \"yes\":\n",
        "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "        # Check question-answering\n",
        "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
        "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
        "            # どちらの判定も \"yes\" だった場合\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
        "            # 回答が適正でなかった場合\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
        "        # 回答がハルシネーションと判定され場合\n",
        "        return \"not supported\""
      ],
      "metadata": {
        "id": "T_rfnirE8ZLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph を構成する"
      ],
      "metadata": {
        "id": "tDy59iM6GhS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langgraph.constants import END\n",
        "\n",
        "# Graph のインスタンスを作成\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Graph に Node を追加\n",
        "workflow.add_node(\"web_search\", web_search)  # web search\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "workflow.add_node(\"generate\", generate)  # generatae\n",
        "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
        "\n",
        "# Graph に Edge を追加\n",
        "workflow.set_conditional_entry_point(\n",
        "    route_question,\n",
        "    # route_question の出力に応じて次にどのノードに進むか分岐\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    # decide_to_generate の出力に応じて次にどのノードに進むか分岐\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    # grade_generation_v_documents_and_question の出力に応じて次にどのノードに進むか分岐\n",
        "    {\n",
        "        \"not supported\": \"generate\",\n",
        "        \"useful\": END,\n",
        "        \"not useful\": \"transform_query\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Graph をコンパイル\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "QpWLF49jBOCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph を可視化"
      ],
      "metadata": {
        "id": "BEh_CsnCfMNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "TlUgEUMdHpYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## グラフを実行する"
      ],
      "metadata": {
        "id": "MLP32bFjGsmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User Question\n",
        "# inputs = {\n",
        "#     \"question\": \"プロンプトエンジニアリングの手法を3つ挙げてください。\"\n",
        "# }\n",
        "\n",
        "inputs = {\n",
        "    \"question\": \"ももいろクローバーZのメンバーの名前を教えてください。\"\n",
        "}\n",
        "\n",
        "value = {}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        print(f\"Node '{key}': Done\")\n",
        "    print(\"---\")\n",
        "\n",
        "# Final generation\n",
        "print(value[\"generation\"])"
      ],
      "metadata": {
        "id": "BGum6EGCGdqR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}