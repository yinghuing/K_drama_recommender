{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yinghuing/K_drama_recommender/blob/master/chapter2/openai_api_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 0: ハンズオンの準備\n",
        "---"
      ],
      "metadata": {
        "id": "aeU0VqdXy8kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API キーの設定\n",
        "*  左ナビゲーションで [**シークレット**] アイコン (鍵形のアイコン) をクリックします。\n",
        "*  [**新しいシークレットを追加**] をクリックし、[**名前**] に `OPENAI_API_KEY` と入力し、その [**値**] に指定されたキーを入力します。\n",
        "*  設定したシークレットの [**ノートブックからのアクセス**] を有効にします。\n",
        "*  入力が完了したら、下のセルを実行します。"
      ],
      "metadata": {
        "id": "f58Tk1yFfJgh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrWQTLn70Ra"
      },
      "source": [
        "# Section 1: トークン\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6fSq7bc8DES"
      },
      "source": [
        "## Tokenizerとtiktoken\n",
        "- LLM などの自然言語処理を行う機械学習モデルは、テキストをトークンという単位で処理する。\n",
        "- テキストデータなどをトークン化 (tokenize) するプログラムを **Tokenizer** という。\n",
        "- トークン化の仕方や入力可能なトークン数は LLM によって異なり、入力するトークン数に応じて API 利用料金が課金される。\n",
        "- **tiktoken** は OSS の高速な Tokenizer である。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9MPred-0se6z"
      },
      "outputs": [],
      "source": [
        "# !pip -q install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JCcxGOsIeksm",
        "outputId": "9a003ff1-5879-45f7-bc06-f058b4d0a234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install tiktoken==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep tiktoken"
      ],
      "metadata": {
        "id": "dJwNysHKOkrZ",
        "outputId": "f9f2892e-1dd5-4637-e2bb-91c977ece1f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken==0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "p8HvU1MfCJDs",
        "outputId": "b72911d9-1869-4b64-93cc-e775a513d92c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==1.3.0\n",
            "aiohappyeyeballs==2.6.1\n",
            "aiohttp==3.11.13\n",
            "aiosignal==1.3.2\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.23\n",
            "albumentations==2.0.5\n",
            "ale-py==0.10.2\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.7.1\n",
            "arviz==0.20.0\n",
            "astropy==7.0.1\n",
            "astropy-iers-data==0.2025.3.10.0.29.26\n",
            "astunparse==1.6.3\n",
            "atpublic==4.1.0\n",
            "attrs==25.3.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.13.3\n",
            "betterproto==2.0.0b6\n",
            "bigframes==1.38.0\n",
            "bigquery-magics==0.8.0\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==1.2.0\n",
            "blosc2==3.2.0\n",
            "bokeh==3.6.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.44\n",
            "branca==0.8.1\n",
            "CacheControl==0.14.2\n",
            "cachetools==5.5.2\n",
            "catalogue==2.0.10\n",
            "certifi==2025.1.31\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.1\n",
            "chex==0.1.89\n",
            "clarabel==0.10.0\n",
            "click==8.1.8\n",
            "cloudpathlib==0.21.0\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.6\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contourpy==1.3.1\n",
            "cramjam==2.9.1\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.2.post1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cudf-polars-cu12==25.2.2\n",
            "cufflinks==0.17.3\n",
            "cuml-cu12==25.2.1\n",
            "cupy-cuda12x==13.3.0\n",
            "cuvs-cu12==25.2.1\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.3\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2024.12.1\n",
            "dask-cuda==25.2.0\n",
            "dask-cudf-cu12==25.2.2\n",
            "dask-expr==1.1.21\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.4.2\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "Deprecated==1.2.18\n",
            "diffusers==0.32.2\n",
            "distributed==2024.12.1\n",
            "distributed-ucxx-cu12==0.42.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.9\n",
            "docker-pycreds==0.4.0\n",
            "docstring_parser==0.16\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.1.3\n",
            "earthengine-api==1.5.6\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.1\n",
            "einops==0.8.1\n",
            "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.12.2\n",
            "etuples==0.3.9\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.7.19\n",
            "fastcore==1.7.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "filelock==3.17.0\n",
            "firebase-admin==6.6.0\n",
            "Flask==3.1.0\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.4\n",
            "folium==0.19.5\n",
            "fonttools==4.56.0\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.5.0\n",
            "fsspec==2024.10.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.10.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.44\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.24.2\n",
            "google-api-python-client==2.160.0\n",
            "google-auth==2.38.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.79.0\n",
            "google-cloud-bigquery==3.29.0\n",
            "google-cloud-bigquery-connection==1.18.1\n",
            "google-cloud-bigquery-storage==2.29.1\n",
            "google-cloud-bigtable==2.29.0\n",
            "google-cloud-core==2.4.3\n",
            "google-cloud-dataproc==5.18.0\n",
            "google-cloud-datastore==2.20.2\n",
            "google-cloud-firestore==2.20.1\n",
            "google-cloud-functions==1.19.0\n",
            "google-cloud-iam==2.18.1\n",
            "google-cloud-language==2.16.0\n",
            "google-cloud-pubsub==2.28.0\n",
            "google-cloud-resource-manager==1.14.1\n",
            "google-cloud-spanner==3.53.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-translate==3.19.0\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.6.0\n",
            "google-genai==1.4.0\n",
            "google-generativeai==0.8.4\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "google-spark-connect==0.5.2\n",
            "googleapis-common-protos==1.69.1\n",
            "googledrivedownloader==1.1.0\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.1\n",
            "grpc-google-iam-v1==0.14.1\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.71.0\n",
            "grpcio-status==1.62.3\n",
            "grpclib==0.4.7\n",
            "gspread==6.1.4\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "gymnasium==1.1.1\n",
            "h11==0.14.0\n",
            "h2==4.2.0\n",
            "h5netcdf==1.6.1\n",
            "h5py==3.12.1\n",
            "hdbscan==0.8.40\n",
            "highspy==1.9.0\n",
            "holidays==0.68\n",
            "holoviews==1.20.2\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.7\n",
            "httpimport==1.4.1\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.28.1\n",
            "humanize==4.11.0\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.2.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.13.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.6.1\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "inflect==7.5.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2025.0.5\n",
            "intel-openmp==2025.0.5\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.5.2\n",
            "jax-cuda12-pjrt==0.5.1\n",
            "jax-cuda12-plugin==0.5.1\n",
            "jaxlib==0.5.1\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.6\n",
            "jiter==0.9.0\n",
            "joblib==1.4.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.0.2\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2024.10.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.3.10\n",
            "keras==3.8.0\n",
            "keras-hub==0.18.1\n",
            "keras-nlp==0.18.1\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.8\n",
            "langchain==0.3.20\n",
            "langchain-core==0.3.44\n",
            "langchain-text-splitters==0.3.6\n",
            "langcodes==3.5.0\n",
            "langsmith==0.3.13\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl\n",
            "libcugraph-cu12==25.2.0\n",
            "libcuml-cu12==25.2.1\n",
            "libcuvs-cu12==25.2.1\n",
            "libkvikio-cu12==25.2.1\n",
            "libraft-cu12==25.2.0\n",
            "librosa==0.10.2.post1\n",
            "libucx-cu12==1.18.0\n",
            "libucxx-cu12==0.42.0\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.3.1\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.2\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==3.1.2\n",
            "mizani==0.13.1\n",
            "mkl==2025.0.1\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.4\n",
            "more-itertools==10.6.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.0\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.12\n",
            "music21==9.3.0\n",
            "namex==0.0.8\n",
            "narwhals==1.30.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.2.0\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.4.2\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numba-cuda==0.2.0\n",
            "numexpr==2.10.2\n",
            "numpy==2.0.2\n",
            "nvidia-cublas-cu12==12.5.3.2\n",
            "nvidia-cuda-cupti-cu12==12.5.82\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.5.82\n",
            "nvidia-cuda-runtime-cu12==12.5.82\n",
            "nvidia-cudnn-cu12==9.3.0.75\n",
            "nvidia-cufft-cu12==11.2.3.61\n",
            "nvidia-curand-cu12==10.3.6.82\n",
            "nvidia-cusolver-cu12==11.6.3.83\n",
            "nvidia-cusparse-cu12==12.5.1.3\n",
            "nvidia-cusparselt-cu12==0.6.2\n",
            "nvidia-ml-py==12.570.86\n",
            "nvidia-nccl-cu12==2.21.5\n",
            "nvidia-nvcomp-cu12==4.2.0.11\n",
            "nvidia-nvjitlink-cu12==12.5.82\n",
            "nvidia-nvtx-cu12==12.4.127\n",
            "nvtx==0.2.11\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.2.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.61.1\n",
            "opencv-contrib-python==4.11.0.86\n",
            "opencv-python==4.11.0.86\n",
            "opencv-python-headless==4.11.0.86\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.31.0\n",
            "opentelemetry-sdk==1.31.0\n",
            "opentelemetry-semantic-conventions==0.52b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.4\n",
            "optree==0.14.1\n",
            "orbax-checkpoint==0.11.8\n",
            "orjson==3.10.15\n",
            "osqp==0.6.7.post3\n",
            "packaging==24.2\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.28.0\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.6.1\n",
            "param==2.2.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==1.0.1\n",
            "peewee==3.17.9\n",
            "peft==0.14.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.1.0\n",
            "platformdirs==4.3.6\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.5.0\n",
            "ply==3.11\n",
            "polars==1.21.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.9\n",
            "prettytable==3.15.1\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.21.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.50\n",
            "propcache==0.3.0\n",
            "prophet==1.1.6\n",
            "proto-plus==1.26.1\n",
            "protobuf==4.25.6\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==18.1.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.10.6\n",
            "pydantic_core==2.27.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.21.3\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.17.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==25.2.0\n",
            "pylibraft-cu12==25.2.0\n",
            "pymc==5.21.1\n",
            "pymystem3==0.2.0\n",
            "pynndescent==0.5.13\n",
            "pynvjitlink-cu12==0.5.2\n",
            "pynvml==12.0.0\n",
            "pyogrio==0.10.0\n",
            "Pyomo==6.8.2\n",
            "PyOpenGL==3.1.9\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.1\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.1\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.5\n",
            "pytensor==2.28.3\n",
            "pytest==8.3.5\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.1\n",
            "pyviz_comms==3.0.4\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post5\n",
            "raft-dask-cu12==25.2.0\n",
            "rapids-dask-dependency==25.2.0\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.3\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==25.2.0\n",
            "rpds-py==0.23.1\n",
            "rpy2==3.5.17\n",
            "rsa==4.9\n",
            "safetensors==0.5.3\n",
            "scikit-image==0.25.2\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.14.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7.post2\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.4.1\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.22.0\n",
            "setproctitle==1.3.5\n",
            "shap==0.46.0\n",
            "shapely==2.0.7\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.7\n",
            "simplejson==3.20.1\n",
            "simsimd==6.2.1\n",
            "six==1.17.0\n",
            "sklearn-compat==0.1.3\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart-open==7.1.0\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.8.4\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.3\n",
            "Sphinx==8.1.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.39\n",
            "sqlglot==25.6.1\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.4\n",
            "stringzilla==3.12.3\n",
            "sympy==1.13.1\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.0.0\n",
            "tblib==3.0.0\n",
            "tcmlib==1.2.0\n",
            "tenacity==9.0.0\n",
            "tensorboard==2.18.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.18.0\n",
            "tensorflow-datasets==4.9.8\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.16.1\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.18.1\n",
            "tensorstore==0.1.72\n",
            "termcolor==2.5.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.18.0\n",
            "thinc==8.3.4\n",
            "threadpoolctl==3.6.0\n",
            "tifffile==2025.2.18\n",
            "tiktoken==0.8.0\n",
            "timm==1.0.15\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.21.1\n",
            "toml==0.10.2\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.48.3\n",
            "treelite==4.4.1\n",
            "treescope==0.1.9\n",
            "triton==3.2.0\n",
            "tweepy==4.15.0\n",
            "typeguard==4.4.2\n",
            "typer==0.15.2\n",
            "types-pytz==2025.1.0.20250204\n",
            "types-setuptools==76.0.0.20250313\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2025.1\n",
            "tzlocal==5.3.1\n",
            "uc-micro-py==1.0.3\n",
            "ucx-py-cu12==0.42.0\n",
            "ucxx-cu12==0.42.0\n",
            "umap-learn==0.5.7\n",
            "umf==0.9.1\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.3.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.19.8\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==14.2\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.2\n",
            "xarray==2025.1.2\n",
            "xarray-einstats==0.8.0\n",
            "xgboost==2.1.4\n",
            "xlrd==2.0.1\n",
            "xyzservices==2025.1.0\n",
            "yarl==1.18.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.54\n",
            "zict==3.0.0\n",
            "zipp==3.21.0\n",
            "zstandard==0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WWdpn2pw8NGp",
        "outputId": "3237fe4f-0787-4389-b71a-a5c04d27f149",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vwIhYtWcshOY",
        "outputId": "c082f17d-152c-4fda-9275-b603d64c8fce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n"
          ]
        }
      ],
      "source": [
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P56iAwzT8Xmq"
      },
      "source": [
        "# Section 2: OpenAI API の利用\n",
        "---\n",
        "\n",
        "### プロンプト設計のためのサイト\n",
        "- [OpenAI Platform](https://platform.openai.com/playground/chat?models=gpt-4o-mini)\n",
        "- [Google AI Studio](https://aistudio.google.com/)\n",
        "- [Anthropic Console](https://console.anthropic.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0l8ptIe8iH5"
      },
      "source": [
        "## Chat Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R8jT7MNRC9t"
      },
      "outputs": [],
      "source": [
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install openai==1.54.4"
      ],
      "metadata": {
        "id": "93qEpG4ZhPZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep openai"
      ],
      "metadata": {
        "id": "ckL-ONQNOo1N",
        "outputId": "8e4de52d-ded3-4b85-9b31-93a37c61bce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai==1.61.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTD-Xe9G8r6w"
      },
      "source": [
        "### Chat Completions APIの呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KHJUSC61Wg_y",
        "outputId": "73519ff2-1d8f-4286-97b2-a8c679c8c354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello, John! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "xTUP-UfSDnLD",
        "outputId": "54e0d5d5-69ae-41b5-bed8-81f5cbfde9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, John! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2THywRt8t0F"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Yk5Cc6rtWtub",
        "outputId": "c7f2342e-db90-412d-c7ff-5ecb5cc97c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Yes, you mentioned that your name is John. How can I help you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello John! How can I assist you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do you know my name?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRqvj0u8xWL"
      },
      "source": [
        "### ストリーミングで応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V7J2Gq9PYPBA",
        "outputId": "5fe988d3-5e1e-4d1c-ee7e-3bebbef35fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI（人工知能）とは、人間の知能を模倣することを目指したコンピュータシステムやプログラムのことを指します。AIは、さまざまな技術や手法を用いて、データの解析、パターン認識、意思決定、自然言語処理、画像認識などのタスクを実行します。\n",
            "\n",
            "AIは大きく分けて二つのカテゴリに分類されます：\n",
            "\n",
            "1. **狭義のAI（Weak AI）**: 特定のタスクを実行することに特化しているAIです。例えば、音声アシスタントや画像認識ソフトウェアがこれに含まれます。\n",
            "\n",
            "2. **汎用AI（Strong AI）**: 人間のように広範な知識や能力を持ち、さまざまなタスクを自律的に遂行できるAIを指します。現在のところ、汎用AIは理論的な概念に留まっており、実用化されていません。\n",
            "\n",
            "AI技術には、機械学習（ML）、深層学習（DL）、自然言語処理（NLP）などが含まれ、それぞれ特定のアプローチや手法を用いています。AIは医療、金融、製造業、エンターテインメントなど、さまざまな分野で活用され、効率性の向上や新しいビジネスチャンスの創出に寄与しています。"
          ]
        }
      ],
      "source": [
        "stream = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"あなたは AI や機械学習に精通したプロフェッショナルです。\"},\n",
        "        {\"role\": \"user\", \"content\": \"AI とは何ですか。\"}\n",
        "  ],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "        print(chunk.choices[0].delta.content, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrlT300r83MS"
      },
      "source": [
        "# Section 3: Function calling\n",
        "---\n",
        "Function Calling に対応しているモデルでは、利用可能な関数の情報をモデルに渡すことで、モデルに必要に応じた関数の利用を選択させることができる。\n",
        "\n",
        "(※ 以下では [OpenAI の公式ドキュメント](https://platform.openai.com/docs/guides/function-calling) をもとに一部改変したコードを使用している)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数を用意する  \n",
        "天気予報の情報を出力する関数  \n",
        "(実際に外部の天気予報サービスを利用するのではなく、既定の予報を返す疑似的な天気予報の関数)"
      ],
      "metadata": {
        "id": "4-ujhSxGPQtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "K97Pbcw3bly8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def get_current_weather(location, unit=\"celsius\"):\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"25\",\n",
        "        \"unit\": \"celsius\",\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数のリストを定義する\n",
        "- 利用可能な関数のリストを定義する。  \n",
        "- それぞれの関数については、辞書で関数名や関数についての説明、関数を呼び出す際のパラメータ等を定義する。  \n",
        "- 下の例では、`tools` という名前のリストに要素として関数が 1 つだけ入っている。"
      ],
      "metadata": {
        "id": "gYGMoEgxlSOD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PgIGMKtBgeGj"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. Tokyo\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数のリストを渡して LLM を呼び出す"
      ],
      "metadata": {
        "id": "rPOkQw20QqrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pO-VYo7tghih",
        "outputId": "26ec7171-4efb-4812-afa4-5bfab8374f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8F6D8qQwyGaAxQj9AiK2pbeq', function=Function(arguments='{\"location\":\"Tokyo\"}', name='get_current_weather'), type='function')], annotations=[])\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        ")\n",
        "\n",
        "print(response.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.tool_calls)"
      ],
      "metadata": {
        "id": "h_9V1fGlR-g8",
        "outputId": "7064f470-e305-4984-9058-16aafbac8120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ChatCompletionMessageToolCall(id='call_8F6D8qQwyGaAxQj9AiK2pbeq', function=Function(arguments='{\"location\":\"Tokyo\"}', name='get_current_weather'), type='function')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.tool_calls[0].function.name)\n",
        "print(response.choices[0].message.tool_calls[0].function.arguments)"
      ],
      "metadata": {
        "id": "JMVsVq0pUfkc",
        "outputId": "2d818c7e-f9a6-4215-d251-4312ac25db05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get_current_weather\n",
            "{\"location\":\"Tokyo\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LLM が関数を使用することを選択した場合、使用する関数の名前や関数を呼び出す際のパラメータを回答する。\n",
        "- LLM は `tools` で定義されている関数の `name` や `description` 、`parameters` を参照して回答を生成する。"
      ],
      "metadata": {
        "id": "M4ycwjPEYxlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数を実行する  \n",
        "- 上記の LLM の回答から関数名やパラメータを取得し、関数を実行する"
      ],
      "metadata": {
        "id": "FfaJaXAWZwP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "c7LcVydmhlp0",
        "outputId": "12458003-4f9d-47f8-ba78-3deac61bc58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"location\": \"Tokyo\", \"temperature\": \"25\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\"]}\n"
          ]
        }
      ],
      "source": [
        "response_message = response.choices[0].message\n",
        "tool_call = response_message.tool_calls[0]\n",
        "\n",
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "messages.append(response_message)\n",
        "function_name = tool_call.function.name\n",
        "function_to_call = available_functions[function_name]\n",
        "function_args = json.loads(tool_call.function.arguments)\n",
        "function_response = function_to_call(\n",
        "    location=function_args.get(\"location\"),\n",
        "    unit=function_args.get(\"unit\"),\n",
        ")\n",
        "\n",
        "print(function_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 関数の実行結果を `messages` に追加する"
      ],
      "metadata": {
        "id": "IihZ_KKdaWXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xe80yJNwjEJy"
      },
      "outputs": [],
      "source": [
        "messages.append({\n",
        "    \"tool_call_id\": tool_call.id,\n",
        "    \"role\": \"tool\",\n",
        "    \"name\": function_name,\n",
        "    \"content\": function_response,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `messages` を渡して LLM を再度呼び出す"
      ],
      "metadata": {
        "id": "MBGoxlj6af3t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q9QBhpRtgtSW",
        "outputId": "8641a3df-85f8-48b0-cfdf-b280d911e08b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The current weather in Tokyo is 25°C, sunny, and windy.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[])\n"
          ]
        }
      ],
      "source": [
        "second_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(second_response.choices[0].message)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}